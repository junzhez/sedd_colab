{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d04647-ae9f-46f1-b044-8f4f2f1235ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please ignore any warnings while installing the dependencies\n",
    "! pip install torch==2.2.1 torchvision==0.17.1 torchaudio==2.2.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "! pip install datasets\n",
    "! pip install einops==0.7.0\n",
    "! pip install fsspec\n",
    "! pip install git-lfs==1.6\n",
    "! pip install h5py\n",
    "! pip install hydra-core==1.3.2\n",
    "! pip install lightning==2.2.1\n",
    "! pip install nvitop==1.3.2\n",
    "! pip install omegaconf==2.3.0\n",
    "! pip install packaging==23.2\n",
    "! pip install pandas\n",
    "! pip install rich==13.7.1\n",
    "! pip install seaborn==0.13.2\n",
    "! pip install scikit-learn==1.4.0\n",
    "! pip install timm==0.9.16\n",
    "! pip install transformers==4.38.2\n",
    "! pip install triton\n",
    "! pip install wandb==0.13.5\n",
    "! pip install flash-attn==2.5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023b6d19-775e-4eb6-a252-4ce97c2443f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting causal-conv1d==1.1.3.post1\n",
      "  Downloading causal_conv1d-1.1.3.post1.tar.gz (6.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting buildtools\n",
      "  Downloading buildtools-1.0.6.tar.gz (446 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.5/446.5 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ninja in ./.local/lib/python3.10/site-packages (from causal-conv1d==1.1.3.post1) (1.11.1.4)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from causal-conv1d==1.1.3.post1) (23.2)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.10/site-packages (from causal-conv1d==1.1.3.post1) (2.2.1+cu121)\n",
      "Collecting argparse\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting furl\n",
      "  Downloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from buildtools->causal-conv1d==1.1.3.post1) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil in /usr/lib/python3/dist-packages (from buildtools->causal-conv1d==1.1.3.post1) (2.8.1)\n",
      "Collecting redo\n",
      "  Downloading redo-3.0.0-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from buildtools->causal-conv1d==1.1.3.post1) (2.32.4)\n",
      "Collecting simplejson\n",
      "  Downloading simplejson-3.20.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 KB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sqlalchemy\n",
      "  Downloading sqlalchemy-2.0.42-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: twisted in /usr/lib/python3/dist-packages (from buildtools->causal-conv1d==1.1.3.post1) (22.1.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch->causal-conv1d==1.1.3.post1) (3.6.0)\n",
      "Requirement already satisfied: fsspec in /usr/lib/python3/dist-packages (from torch->causal-conv1d==1.1.3.post1) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (12.1.105)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch->causal-conv1d==1.1.3.post1) (1.12)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (12.1.0.106)\n",
      "Requirement already satisfied: triton==2.2.0 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (12.1.105)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch->causal-conv1d==1.1.3.post1) (2.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.3.post1) (10.3.2.106)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/lib/python3/dist-packages (from torch->causal-conv1d==1.1.3.post1) (4.10.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->causal-conv1d==1.1.3.post1) (12.1.105)\n",
      "Requirement already satisfied: six>=1.8.0 in /usr/lib/python3/dist-packages (from furl->buildtools->causal-conv1d==1.1.3.post1) (1.16.0)\n",
      "Collecting orderedmultidict>=1.0.1\n",
      "  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests->buildtools->causal-conv1d==1.1.3.post1) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests->buildtools->causal-conv1d==1.1.3.post1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->buildtools->causal-conv1d==1.1.3.post1) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->buildtools->causal-conv1d==1.1.3.post1) (2020.6.20)\n",
      "Collecting greenlet>=1\n",
      "  Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (582 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.2/582.2 KB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: causal-conv1d, buildtools, docopt\n",
      "  Building wheel for causal-conv1d (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for causal-conv1d: filename=causal_conv1d-1.1.3.post1-cp310-cp310-linux_x86_64.whl size=13921106 sha256=da87cdd61a1a3c2c0e55b7c4304aecd81103ab95b9c688d5487aec488f26e280\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/2f/a0/30/b43f9cf4b5ca677a63a11cda4ebc97667a0dcb4c5ade951a8f\n",
      "  Building wheel for buildtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for buildtools: filename=buildtools-1.0.6-py3-none-any.whl size=512379 sha256=10c29f0b1b37574914cbfc1bb2370f7b6cd7fe4838771d1d3025336197397d6f\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/90/e9/2a/625d99dffa430d0b4293d3d386f63e0eb8edeeb54f3f29d208\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=ef92f3d57aa9c80e62d9067b66860da39d05696a346aea37f549dd8afd91f6f7\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built causal-conv1d buildtools docopt\n",
      "Installing collected packages: redo, docopt, argparse, simplejson, orderedmultidict, greenlet, sqlalchemy, furl, buildtools, causal-conv1d\n",
      "Successfully installed argparse-1.4.0 buildtools-1.0.6 causal-conv1d-1.1.3.post1 docopt-0.6.2 furl-2.1.4 greenlet-3.2.3 orderedmultidict-1.0.1 redo-3.0.0 simplejson-3.20.1 sqlalchemy-2.0.42\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mamba-ssm==1.1.4\n",
      "  Downloading mamba_ssm-1.1.4.tar.gz (34 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: causal_conv1d<1.2.0,>=1.1.0 in ./.local/lib/python3.10/site-packages (from mamba-ssm==1.1.4) (1.1.3.post1)\n",
      "Requirement already satisfied: einops in ./.local/lib/python3.10/site-packages (from mamba-ssm==1.1.4) (0.7.0)\n",
      "Requirement already satisfied: ninja in ./.local/lib/python3.10/site-packages (from mamba-ssm==1.1.4) (1.11.1.4)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from mamba-ssm==1.1.4) (23.2)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.10/site-packages (from mamba-ssm==1.1.4) (2.2.1+cu121)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (from mamba-ssm==1.1.4) (4.38.2)\n",
      "Requirement already satisfied: triton in ./.local/lib/python3.10/site-packages (from mamba-ssm==1.1.4) (2.2.0)\n",
      "Requirement already satisfied: buildtools in ./.local/lib/python3.10/site-packages (from causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (1.0.6)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch->mamba-ssm==1.1.4) (3.6.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (10.3.2.106)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch->mamba-ssm==1.1.4) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (8.9.2.26)\n",
      "Requirement already satisfied: fsspec in /usr/lib/python3/dist-packages (from torch->mamba-ssm==1.1.4) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (12.1.0.106)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch->mamba-ssm==1.1.4) (2.4)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (12.1.105)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch->mamba-ssm==1.1.4) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.10/site-packages (from torch->mamba-ssm==1.1.4) (11.4.5.107)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/lib/python3/dist-packages (from torch->mamba-ssm==1.1.4) (4.10.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm==1.1.4) (12.1.105)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from transformers->mamba-ssm==1.1.4) (1.21.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.local/lib/python3.10/site-packages (from transformers->mamba-ssm==1.1.4) (0.34.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.local/lib/python3.10/site-packages (from transformers->mamba-ssm==1.1.4) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers->mamba-ssm==1.1.4) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers->mamba-ssm==1.1.4) (5.4.1)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from transformers->mamba-ssm==1.1.4) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.10/site-packages (from transformers->mamba-ssm==1.1.4) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers->mamba-ssm==1.1.4) (2025.7.34)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers->mamba-ssm==1.1.4) (1.1.5)\n",
      "Requirement already satisfied: simplejson in ./.local/lib/python3.10/site-packages (from buildtools->causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (3.20.1)\n",
      "Requirement already satisfied: furl in ./.local/lib/python3.10/site-packages (from buildtools->causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (2.1.4)\n",
      "Requirement already satisfied: sqlalchemy in ./.local/lib/python3.10/site-packages (from buildtools->causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (2.0.42)\n",
      "Requirement already satisfied: redo in ./.local/lib/python3.10/site-packages (from buildtools->causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (3.0.0)\n",
      "Requirement already satisfied: docopt in ./.local/lib/python3.10/site-packages (from buildtools->causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (0.6.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/lib/python3/dist-packages (from buildtools->causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (2.8.1)\n",
      "Collecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: twisted in /usr/lib/python3/dist-packages (from buildtools->causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (22.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests->transformers->mamba-ssm==1.1.4) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers->mamba-ssm==1.1.4) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers->mamba-ssm==1.1.4) (2020.6.20)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests->transformers->mamba-ssm==1.1.4) (3.4.2)\n",
      "Requirement already satisfied: six>=1.8.0 in /usr/lib/python3/dist-packages (from furl->buildtools->causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (1.16.0)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in ./.local/lib/python3.10/site-packages (from furl->buildtools->causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (1.0.1)\n",
      "Requirement already satisfied: greenlet>=1 in ./.local/lib/python3.10/site-packages (from sqlalchemy->buildtools->causal_conv1d<1.2.0,>=1.1.0->mamba-ssm==1.1.4) (3.2.3)\n",
      "Building wheels for collected packages: mamba-ssm\n",
      "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mamba-ssm: filename=mamba_ssm-1.1.4-cp310-cp310-linux_x86_64.whl size=137750563 sha256=894c9b80b277c370c36b0c0d93c801394a4d8597c1fc6cede8b270ed32428259\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/5f/fc/b0/c8abc7ab5284080da71acabfbe3969cb7df56217f7cf7e807d\n",
      "Successfully built mamba-ssm\n",
      "Installing collected packages: argparse, mamba-ssm\n",
      "Successfully installed argparse-1.4.0 mamba-ssm-1.1.4\n",
      "\u001b[33mWARNING: Skipping torchao as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: numpy 1.21.5\n",
      "Not uninstalling numpy at /usr/lib/python3/dist-packages, outside environment /usr\n",
      "Can't uninstall 'numpy'. No files were found to uninstall.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "! pip install causal-conv1d==1.1.3.post1\n",
    "! pip install mamba-ssm==1.1.4\n",
    "! pip uninstall -y torchao\n",
    "! pip uninstall -y numpy\n",
    "! pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6507d1-e55e-433b-94ae-f69f04ec01fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Score-Entropy-Discrete-Diffusion'...\n",
      "remote: Enumerating objects: 173, done.\u001b[K\n",
      "remote: Counting objects: 100% (161/161), done.\u001b[K\n",
      "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
      "remote: Total 173 (delta 94), reused 95 (delta 52), pack-reused 12 (from 2)\u001b[K\n",
      "Receiving objects: 100% (173/173), 41.31 KiB | 1.01 MiB/s, done.\n",
      "Resolving deltas: 100% (94/94), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/junzhez/Score-Entropy-Discrete-Diffusion.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4689d1c0-11f4-4b55-a5c5-fa2082fdb036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('Score-Entropy-Discrete-Diffusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "555f8514-f7a0-4a9f-8fa0-0d84f2584e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " come back on in the second two games and he’s probably going to look up a little bit for a lot of guys and those take it’ or his blues get it’. His tangibles were there and their power was just as they need’ be.\n",
      "\n",
      "That momentum led to the sizzling up top unit after Anderson and Lee came along well. That expected power all right then that holding me back. That understanding that ultimately doesn’t end until…\n",
      "\n",
      "my goals.\n",
      "\n",
      "“We bigger of a team that at more of a team level and that’s right back there. We’re getting the times in terms of scoring goals. Different guys itching to score the goals and we’re stepping in and basically have two games out the easiest possible stumps. For me, we have�re still scoring two goals and it’s not necessarily the size of our group to make it one or a couple goals more on average.”\n",
      "\n",
      "Maybe a bit but not the case when you hit in the bottom two and that keeps you in the rankings.\n",
      "\n",
      "We need to see where we take our home games, to get a feel for how to get the ice in that rhythm and everything.\n",
      "\n",
      "Now that Andre Bauer is a kid for the team he is only another guy in the cut for the Sens. With Lee ascending badly and gettin’ and as a franchise one after all, with Anderson and Gill who bring help to the offense that they rely on out there he has some than get it.\n",
      "\n",
      "But you just have to be fast on this slowly over the next few years and hopefully future ones.\n",
      "\n",
      "So that’s players shaming and their ways, I’m watching the tape.<|endoftext|>On July 19, 2017, former vice president of state Hillary Clinton took to Twitter about his negative approach of Trump whether it came from someone smarter than me.\n",
      "\n",
      "“As you witnessed tonight, Mr. Mr. Clinton, with Mr. President, I’ve said some very good things about you and all I am saying is that ‘tin on the floor is the right man’,” Trump said, referring to one of the speakers in the room. “I can trust your candidate enough to say totally: She [Hillarys] isn’t really lying. She’s ‘really all’.”\n",
      "\n",
      "I am wrong. https://t.co/jQxxxvmm1 — Donald Trump Jr. (@realDonaldTrumpTrump) July 19, 2016\n",
      "\n",
      "Trump came at Clinton to accuse him of using “fake news” for what isn’t exactly a bit of criticism for an opponent of the Republican president. The former congresswoman, medical engineer, and UCLA student described her chat Monday with Meapsundit’s podcast Tuesday night regarding her relationship with Donald Trump.\n",
      "\n",
      "“Last night, believe me, it looks like, I believe with you: My son, Donalds, told the recently, I,” Trump said at the time. “You point trust the stories and I don’t seem to deep down believe those people� stories either.”\n",
      "\n",
      "Trump does refer to the guests who asked about her running mate’s upbringing, and that Trump served in one of the most effectively equipped surrogate roles in politics with a GOP committee that sees him as an international terrorist.\n",
      "\n",
      "Andrew is a New York Times bestselling author. He wrote the latest book about the Messiah. Follow him on Twitter @kimkingwain and @drommel.<|endoftext|>An unofficial campaign adviser joined Trump calling himself an emergency adviser after the Trump (R) strategist ousted in October 2016, shortly after he wurked his confidence in the 2016 election.\n",
      "\n",
      "Story Continued Below\n",
      "\n",
      "Wilfully asked Friday to address the help he has gotten from Trump since the incident, he answered: “I offer advice. I do, you know, make sure it happened.”\n",
      "\n",
      "The strategist likened being an emergency adviser to the ongoing\n",
      "\n",
      "“Well you know, how bad is that team looking to figure out exactly how it worked? Well, on the day of the campaign, the revelations it became are specific. When you look at 1871, you will see that the staff is deeply divided. You are revealing to Donald Trump’s team what’s going on there. In particular, they provide you with the news, from The New Yorker,” Stephen Feldman director,\n",
      "\n",
      "Mark Hollendone added.\n",
      "\n",
      "Trump leverages frequently a knowledge of who had been and became.\n",
      "\n",
      "“We're never sure who’s in team which,” says Harold Diaz, a\n",
      "\n",
      " strategist, as well as a recent Trump campaign chairman. \"What do you mean in the sense of '… you least came to you with information,' if it weren't an\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from load_model import load_model\n",
    "from transformers import GPT2TokenizerFast\n",
    "import torch.nn.functional as F\n",
    "import sampling\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model, graph, noise = load_model(\"louaaron/sedd-small\", device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "\n",
    "sampling_fn = sampling.get_pc_sampler(\n",
    "    graph, noise, (1, 1024), 'hamiltonian', 100, device=device, threshold=False, N=100, temp = 0.00001\n",
    ")\n",
    "\n",
    "samples = sampling_fn(model)\n",
    "\n",
    "text_samples = tokenizer.batch_decode(samples)\n",
    "for i in text_samples:\n",
    "    print(i)\n",
    "    print(\"=================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e58f298-4ac3-42c8-8ccf-d06da219fc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 62.714.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import os.path\n",
    "import gc\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import data\n",
    "import losses\n",
    "import sampling\n",
    "import graph_lib\n",
    "import noise_lib\n",
    "import utils\n",
    "from model import SEDD\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "\n",
    "eval_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device).eval()\n",
    "batches = samples.shape[0]\n",
    "total_perplexity = 0\n",
    "\n",
    "for i in range(batches):\n",
    "    s = samples[i:(i+1)]\n",
    "    loss, logits = eval_model(s, labels=s)[:2]\n",
    "    logits = logits.transpose(-1, -2)\n",
    "    perplexity = F.cross_entropy(logits[..., :-1], s[..., 1:], reduction=\"none\").mean(dim=-1).exp().mean()\n",
    "    total_perplexity += perplexity\n",
    "    \n",
    "total_perplexity /= batches\n",
    "print(f\"Perplexity: {total_perplexity:.3f}.\")\n",
    "\n",
    "del model, eval_model, logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e13542d-1867-45e7-9c44-afb825e55021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.98963333333334 74.92609999999999 70.99656666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "perp_1 = [94.103, 68.907, 65.602, 74.418, 96.940, 52.100, 81.539, 85.054, 82.747, 75.594, \n",
    "          76.452, 83.203, 44.899, 105.597, 146.895, 80.415, 62.490, 77.831, 81.683, 107.688,\n",
    "          113.508, 105.739, 83.122, 67.270, 61.389, 73.907, 88.900, 99.478, 113.463, 98.756]\n",
    "\n",
    "perp_2 = [86.998, 102.511, 70.878, 103.050, 75.732, 77.600, 50.410, 50.410, 70.344, 76.551, \n",
    "          62.318, 53.003, 60.942, 92.526, 47.596, 121.434, 63.802, 80.459, 72.857, 83.163,\n",
    "          69.002, 61.488, 100.153, 88.646, 48.669, 64.114, 110.040, 65.142, 73.024, 64.921]\n",
    "\n",
    "perp_3 = [72.083, 65.843, 79.915, 65.303, 88.818, 113.376, 71.311, 70.863, 63.406, 63.662,\n",
    "          63.205, 83.615, 48.511, 113.397, 65.122, 76.617, 79.306, 60.454, 74.206, 42.606,\n",
    "          63.625, 71.147, 117.662, 35.393, 62.504, 76.446, 85.013, 52.842, 40.932, 62.714]\n",
    "\n",
    "print(np.mean(perp_1), np.mean(perp_2), np.mean(perp_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ef1f5-14b6-4a6d-bb7c-193915d9f092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sedd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
